{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05fc5dd4",
   "metadata": {},
   "source": [
    "# Assignment 2: Advanced Legal Analytics (LAW 3027)\n",
    "\n",
    "\n",
    "### Note: This is an individual assignment and you should provide only your own answer to the questions.\n",
    "\n",
    "####  Assignment Instructions:\n",
    "\n",
    "##### 1. Write the python code to complete the following tasks. (You should use markdown cells to answer the questions which require text or interpretation of results. )\n",
    "\n",
    "##### 2. You should import the relevant python libraries needed for various tasks.\n",
    "\n",
    "##### 3. All the python libraries you may need have been covered during the course.  \n",
    "\n",
    "##### 4. Comment your code as much as possible. Mention the question number in the markdown cell before you write the code in the code cell. \n",
    "\n",
    "##### 5. Feel free to use the same notebook and mention your answers/code below each question. \n",
    "\n",
    "##### 6.  NOTE ABOUT FIGURES : In order for all the images to be displayed in your local Jupyter notebook make sure that you also download the folder called `figs` and save it in the same folder where this notebook is saved.  The `figs` folder can be downloaded from here: https://github.com/maastrichtlawtech/law3027-advanced-legal-analytics/tree/main/assignments \n",
    "\n",
    "#### 7. You are not allowed to distribute or share the assignment with anyone. The assignment is available on the github page of the course only to ensure easy readability of the images in the last 2 questions. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f70a817",
   "metadata": {},
   "source": [
    "## Q1.  Classification of Semantic Norms from GDPR (3.5 points)\n",
    "Robaldo et al. [1] developed a knowledge base which formalized semantic norms such as permissions, obligations and constitutive rules from the General Data Protection Regulation (GDPR) in LegalRuleML, an XML formalism designed to represent the logical content of legal documents. We have programatically extracted a subset of this knowledge base for the purpose of this exercise. \n",
    "\n",
    "We will just focus on two categories of legal norms: obligations and permissions. \n",
    "\n",
    "- Obligations: An obligation indicates what someone is obliged to do. For example, the following fragment of the Italian privacy law taken from [2]: \"A controller intending to process personal data falling within the scope of application of this Act shall have to notify the \"Garante\" ... \"\n",
    "\n",
    "- Permissions: a permission indicates that someone is not prohibited from doing something. For example, \"Member States may adopt or maintain additional pre-contractual information requirements for contracts to which this Article applies.\"\n",
    "\n",
    "The extracted dataset is available here: https://raw.githubusercontent.com/maastrichtlawtech/law3027-advanced-legal-analytics/main/data/gdpr_provision_classification_assignment.csv \n",
    "\n",
    "\n",
    "The dataset contains some articles and their corresponding paragraphs from the GDPR. The `text` column contains the text of that particular paragraph. The `labels` refer to the type of the semantic norm present in the given `text`.\n",
    "\n",
    "\n",
    "- **0 means that the text is a permission**\n",
    "- **1 means text is an obligation**\n",
    "\n",
    "\n",
    "In this exercise, you will train a machine learning classifier to automatically classify/annotate some of the GDPR provisions. Semantic annotation is the process of augmenting a text with labels expressing its semantic content (semantic norm in this case). Enriching legal texts with semantic tags can help in legal information retrieval.\n",
    "\n",
    "\n",
    "[1] Robaldo, L., Bartolini, C., & Lenzini, G. (2020, May). The DAPRECO knowledge base: representing the GDPR in LegalRuleML. In Proceedings of The 12th Language Resources and Evaluation Conference (pp. 5688-5697).\n",
    "\n",
    "[2] Biagioli, C., Francesconi, E., Passerini, A., Montemagni, S., & Soria, C. (2005, June). Automatic semantics extraction in law documents. In Proceedings of the 10th international conference on Artificial intelligence and law (pp. 133-140).\n",
    "\n",
    "\n",
    "Specific tasks you need to perform to complete this question:\n",
    "\n",
    "- Read the dataset using pandas DataFrame into a dataframe called `df`. \n",
    "\n",
    "\n",
    "- Plot the number of class labels in the dataset: The count of the column `labels` to illustrate how many permissions and obligations are in the dataset.\n",
    "\n",
    "\n",
    "- Clean the `text` column of the DataFrame: Remove the punctuation, lowercase the text, remove the newlines (if any) and remove all numbers.  After doing these operations print the `text` column by converting it to a list to see if the data cleaning has been perfomed correctly or not. Use `df['text'].values.tolist()` for this.\n",
    "\n",
    "\n",
    "- Select the variables of interset (predictor and target variables) into a new dataframe called `df_selection`. \n",
    "\n",
    "    - Predictor Variable (or Features) - One or more variables that are used to determine(Predict) the 'Target Variable'.\n",
    "\n",
    "    - Target Variable - A variable that needs to be predicted is a target variable.\n",
    "    - The features in this case are the `text`. The target variable is `labels`.\n",
    "\n",
    "\n",
    "- Convert the `text` to TF-IDF. Use NLTK's default stopwords for English as an input argument for the `TfidfVectorizer`\n",
    "\n",
    "\n",
    "- Split the data into train and test. Set the percentage of training set as 90% and testing set as 10%.\n",
    "\n",
    "\n",
    "- Train the K-nearest neighbour (KNN) (Choose K=3) Classifier and then evaluate it on the testing set. Print the evaluation metrics (confusion matrix, precision, recall, accuracy, F1-score and classification report.) \n",
    "\n",
    "\n",
    "- Record the accuracy of the KNN classifier for different values of K (ranging from 1 to 10). Make a line plot (value of K on X-axis and the accuracy on the Y-axis). What value of K gives the best accuracy ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d461d7d",
   "metadata": {},
   "source": [
    "## Q2 Correlation & Regression Analysis on a Crime Dataset (3.5 points)\n",
    "\n",
    "#### Dataset: \n",
    "\n",
    "We have collected a subset of the crime dataset from UCI Machine Learning Repository. For detailed information about the variables in the dataset you can refer to the link: http://archive.ics.uci.edu/ml/datasets/communities+and+crime+unnormalized \n",
    "\n",
    "The dataset is available here: https://raw.githubusercontent.com/maastrichtlawtech/law3027-advanced-legal-analytics/main/data/crime_dataset_assignment.csv\n",
    "\n",
    "#### Target Variable\n",
    "\n",
    "The target variable of interest is `ViolentCrimesPerPop`. It refers to the total number of violent crimes per 100K popuation (numeric - decimal).\n",
    "\n",
    "#### Sub-Tasks:\n",
    "\n",
    "Specific tasks you need to perform to complete this question:\n",
    "\n",
    "- Load the crime dataset into a pandas DataFrame called `df_crime`\n",
    "\n",
    "\n",
    "- Explore the `df_crime` dataset and find out which `state` has the maximum and the minimum `ViolentCrimesPerPop` ? (Hint: you can use either numerical or visual data representation to find the answer).\n",
    "\n",
    "\n",
    "- Compute a correlation matrix and a heatmap for the `df_crime` dataframe.\n",
    "\n",
    "\n",
    "- Programatically identify the top 5 most correlated variables (features) with `ViolentCrimesPerPop`.  The code should print the correlation values with between `ViolentCrimesPerPop` and the top 5 most correlated features.  Further,  compute the correlation matrix of `ViolentCrimesPerPop` with the 5 most correlated features.  You can always refer here to see the meaning of each variable:  http://archive.ics.uci.edu/ml/datasets/communities+and+crime+unnormalized  \n",
    "\n",
    "\n",
    "- Consider the most correlated variable with `ViolentCrimesPerPop` as the independent variable and `ViolentCrimesPerPop` as the dependent/target variable. Perform a linear regression analysis to predict the `ViolentCrimesPerPop`  using the most correlated variable. \n",
    "   \n",
    "   - Split the dataset as 90% training and 10% test set\n",
    "   - Compute the Mean squared error and Coefficient of Determination on the test set\n",
    "   - Compute the Slope & Intercept\n",
    "   - Plot the predicted values for the test set using the Linear Regression Model. Also plot the acutal test data.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380def6c",
   "metadata": {},
   "source": [
    "## Q3 Suitability of data for Correlation or Regression Analysis (1 point)\n",
    "\n",
    "#### For each of the four scatter plots shown below, discuss whether the data in the figures is suitable for a correlation analysis or linear regression ? (No more than 50 words for each option, A, B, C & D). Therefore the answer including all 4 options should contain a maximum of 200 words\n",
    "\n",
    "- # A![A](figs/fig_r1.png)\n",
    "- # B![B](figs/fig_r2.png)\n",
    "- # C![C](figs/fig_r3.png)\n",
    "- # D![D](figs/fig_r4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1207a977",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Q4. BLIND JUSTICE (2 points)\n",
    "\n",
    "\n",
    "\"In jurisdictions across the United States, prosecutors make highly consequntial charging decisions using police incident reports or narratives that contain information about the race of the suspect. Recent studies have shown that there is reason for concern that the judgments made by the prosecutor may suffer from explicit or implict racial bias.\" quoted and taken from [3]\n",
    "\n",
    "Recently, we have seen works [3] [4] where algorithms have been used to automatically mask race-related information in police incident reports or narratives. Some researchers have developed algorithms to readact explicit mentions of race and other race-related information in the police incident reports or narratives. The two images below present fictional examples from [3][4] of the original and redacted narratives (by the algorithm). You can read the papers for more details. However, the questions below do not necessarily require a reading of the papers:\n",
    "\n",
    "\n",
    "- Q4.1: Let's say you are in-charge of a BLIND JUSTICE project (in a hypothetical jurisdiction - assuming processing of personal data is permitted). The goal of this project is to develop an algorithm to mask the mentions of race and race-related information in the police incident reports or narratives. You have recently finished studying the Advanced Legal Analytics course and you have some ideas on how to implement the system. Based on the various technologies you have learned during the course what technology will you use to implement such a system ? What are the advantages and disadvantages of using regular expressions over named entitity recognition systems to accomplish the above masking task? (Word limit: 150 words)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Q4.2: Compare the outputs A & B in the images below. Which output you think does a better job in implementing fairness and why? (Word limit: 75 words)\n",
    "\n",
    "\n",
    "[3] https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1214/reports/final_reports/report038.pdf\n",
    "\n",
    "[4] https://5harad.com/papers/blind-charging.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d93cd52",
   "metadata": {},
   "source": [
    "- # A![A](figs/blind_justice_1.png)\n",
    "- # B![B](figs/blind_justice_2.png)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
